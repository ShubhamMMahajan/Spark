{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done reading the file.\n",
      "Done creating the node dictionary.\n",
      "Done processing all the data.\n",
      "Calculating the most likely nodes to connect to...\n",
      "The top nodes to connect to are 2, 8.\n"
     ]
    }
   ],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "\n",
    "import pyspark\n",
    "from collections import defaultdict\n",
    "\n",
    "#Creating the spark context\n",
    "sc = pyspark.SparkContext(appName=\"Graph Nodes\")\n",
    "\n",
    "file = open('Slashdot.txt', 'r')\n",
    "\n",
    "print(\"Done reading the file.\")\n",
    "\n",
    "node_connection_dict = defaultdict(list)\n",
    "\n",
    "#Reading all the connections between nodes given in a text file.\n",
    "#Node dictionary format goes as follows: {node: [list of connecting nodes]}\n",
    "for line in file:\n",
    "    words = line.split()\n",
    "   \n",
    "    original_node = words[0]\n",
    "    connecting_node = words[1]\n",
    "    node_connection_dict[original_node].append(connecting_node)\n",
    "\n",
    "print(\"Done creating the node dictionary.\")\n",
    "\n",
    "#The connection final dict has the following format: {node: [list of tuples of all other nodes not connected to the key node]}\n",
    "#                                                                                       |\n",
    "#                                                                                       V\n",
    "#                   (original node, other node, percentage of mutual connections based on original node connections)\n",
    "connection_final_dict = defaultdict(list)    \n",
    "for node in node_connection_dict.keys():\n",
    "    for all_other_nodes in node_connection_dict.keys():\n",
    "        #mutual_connections = 0\n",
    "        if all_other_nodes == node or all_other_nodes in node_connection_dict[node]:            \n",
    "            continue\n",
    "        connection_final_dict[node].append((node, all_other_nodes, len(set(node_connection_dict[node])&set(node_connection_dict[all_other_nodes])) / float(len(set(node_connection_dict[node]) | set(node_connection_dict[all_other_nodes]))) * 100))\n",
    "        \n",
    "print(\"Done processing all the data.\")\n",
    "\n",
    "#Below is a test case for node 1\n",
    "test_run = connection_final_dict[\"1\"]\n",
    "\n",
    "#creating an rdd for the dictionary with the key of node 1\n",
    "node_1 = sc.parallelize(test_run)\n",
    "\n",
    "\n",
    "print(\"Calculating the most likely nodes to connect to...\")\n",
    "\n",
    "#finds the top 2 nodes with the most mutual connections\n",
    "top = node_1.top(2, key = lambda s: s[2])\n",
    "\n",
    "#formats the output string to indicate the user which are the top 2 connections\n",
    "s = \"The top nodes to connect to are \"\n",
    "for tuples in top:\n",
    "    s += str(tuples[1]) + \", \"\n",
    "s = s.rstrip(\", \")\n",
    "s += \".\"\n",
    "print(s)\n",
    "\n",
    "#closes the spark connection\n",
    "sc.stop()\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
